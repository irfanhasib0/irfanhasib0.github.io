Here I have added my machine learning projects.

### Neural Network :: NN Implementation from scratch with raw python.
* ![NN Implementation from scratch - Notebook (Project Presentation and Code Link) ](https://github.com/irfanhasib0/Machine-Learning/blob/master/Machine_Learning_Algo_From_Scratch/ID3_with_continuous_feature_support_exp.py)

* Forward Propagation
* Backward Propagation


* a. Forward Propagation b. Back Propagation (Click on image for full resolution and clear view on a new tab)

<img src="https://github.com/irfanhasib0/Machine-Learning/blob/master/docs/Algorihms/NN_fp.jpg" align="left"
     title="Schematics" width="420" height="420">
<img src="https://github.com/irfanhasib0/Machine-Learning/blob/master/docs/Algorihms/NN_bp.jpg" align="center"
     title="(Click on image for full resolution and clear view on a new tab)" width="420" height="420">

c. Result of ANN implementation for XOR data - mean sqaure error vs epoch -

<img src="https://github.com/irfanhasib0/Machine-Learning/blob/master/docs/Results/xor_ann.jpg" align="center"
     title="(Click on image for full resolution and clear view on a new tab)" width="320" height="240">


### Decision Tree :: ID3 Implementation from scratch with continuous data split based on entropy and information gain.
* [ID3 Implementation from scratch - Notebook (Project Presentation and Code Link) ](https://github.com/irfanhasib0/Machine-Learning/blob/master/Machine_Learning_Algo_From_Scratch/ANN_From_Scratch_modular_class.ipynb)

* Titanic and irish dataset was used for testing ID3.
* Continuous data spliting based on information gain.
* ID3 Algorithm with recursion. Best attribute was calculated based on information gain.
* Prediction : accuracy,precision,recall reporting.

* ID3 Flow Chart of Implementation (Click on image for full resolution and clear view on a new tab)

<img src="https://github.com/irfanhasib0/Machine-Learning/blob/master/docs/Algorihms/ID3.jpg" align="center"
     title="(Click on image for full resolution and clear view on a new tab)
" width="320" height="240">

* Result of ID3 implementation for iris data - a.Precision Recall and Accuracy and b.True Label vs Prediction -


<img src="https://github.com/irfanhasib0/Machine-Learning/blob/master/docs/Results/iris_ID3.png" align="left"
     title="(Click on image for full resolution and clear view on a new tab)
" width="320" height="240">

<img src="https://github.com/irfanhasib0/Machine-Learning/blob/master/docs/Results/irispred.jpg" align="center"
     title="(Click on image for full resolution and clear view on a new tab)
" width="320" height="240">

* Result of ID3 implementation for Titanic data - a.Precision Recall and Accuracy and b.True Label vs Predictio

<img src="https://github.com/irfanhasib0/Machine-Learning/blob/master/docs/Results/titanic_ID3.png" align="left"
     title="(Click on image for full resolution and clear view on a new tab)
" width="320" height="240">

<img src="https://github.com/irfanhasib0/Machine-Learning/blob/master/docs/Results/titanicpred.jpg" align="center"
     title="(Click on image for full resolution and clear view on a new tab)
" width="320" height="240">



### Naive Bayes :: Implementation for text classification.
* ![Naive Bayes Implementation from scratch - Notebook (Project Presentation and Code Link) ](https://github.com/irfanhasib0/Machine-Learning/blob/master/Machine_Learning_Algo_From_Scratch/Naive_Bayes_Stack_Exchange.ipynb)

* Archived data from stack exchange is used for classification.
* Text Preprocessing was done with raw python without nltk.
* Naive Bayes algorithm applied on the procesed text.
<img src="https://github.com/irfanhasib0/Machine-Learning/blob/master/docs/Algorihms/Naive Bayes.jpg" align="center"
     title="Schematics" width="640" height="480">

